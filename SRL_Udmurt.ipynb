{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordlist_file = open('parsed.txt', 'r', encoding = 'utf-8').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordlist = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#здесь собираются все возможные разборы слов\n",
    "for line in wordlist_file:\n",
    "    word = re.findall('</ana>([^<]*?)</w>', line)\n",
    "    if word:\n",
    "        analyses = re.findall('<ana (.*?)>', line)\n",
    "        if analyses:\n",
    "            wordlist[word[0]] = []\n",
    "            for i in range(len(analyses)):\n",
    "                gr = re.findall('gr=\"(.*?)\"', analyses[i])[0].split(',')\n",
    "                lex = re.findall('lex=\"(.*?)\"', analyses[i])[0]\n",
    "                wordlist[word[0]].append((word[0], lex, tuple(gr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('мужикеным', 'мужик', ('N', 'rus', 'anim', 'hum', 'sg', 'ins', '1sg'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist['мужикеным']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#все признаки существительных\n",
    "grams_N = []\n",
    "for k in wordlist:\n",
    "    for el in wordlist[k]:\n",
    "        if el[2][0] == 'N':\n",
    "            for gr in el[2][1:]:\n",
    "                if gr not in grams_N and 'sg' not in gr and 'pl' not in gr and 'rus' not in gr and 'attr' not in gr and '_' not in gr:\n",
    "                    grams_N.append(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grams_N = ['anim', 'nom', 'ins', 'loc', 'ill', 'el', 'hum', 'PN',\n",
    "           'topn', 'prol', 'vn', 'body', 'adv', 'egr', 'dat', 'acc',\n",
    "           'gen', 'app', 'transport', 'abl', 'car', 'term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#все признаки глаголов\n",
    "grams_V = []\n",
    "for k in wordlist:\n",
    "    for el in wordlist[k]:\n",
    "        if el[2][0] == 'V':\n",
    "            for gr in el[2][1:]:\n",
    "                if gr not in grams_V:\n",
    "                    grams_V.append(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grams_V = ['pst', 'prs', '3', 'tr', 'cvb', 'gen', 'intr', 'with_ill',\n",
    "           'sg', 'fut', 'evid', '2', 'ptcp', 'nom', 'imp', 'pl',\n",
    "           'neg', '1', 'with_el', 'vn', 'with_instr', 'inf',\n",
    "           'with_dat', 'act', 'acc', '3sg', 'with_abl', 'ins',\n",
    "           'with_inf', 'pass', 'deb', 'loc', 'res', 'caus', 'ill',\n",
    "           '1sg', 'adv', 'dur', 'subj', 'el', 'iter', 'impers', 'mult',\n",
    "           '2pl', '3pl', 'dat', 'comp', 'hort', 'abl', '1pl', 'lim',\n",
    "           'egr', '2sg', 'prol', 'detr', 'term', 'car', 'refl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post = {}\n",
    "for line in wordlist_file:\n",
    "    word = re.findall('</ana>([^<]*?)</w>', line)\n",
    "    if word:\n",
    "        analyses = re.findall('<ana (.*?)>', line)\n",
    "        if analyses:\n",
    "            for el in analyses:\n",
    "                gr = re.findall('gr=\"(.*?)\"', el)[0].split(',')\n",
    "                if 'POST' in gr:\n",
    "                    trans = re.findall('trans_ru=\"(.*?)\"', el)[0]\n",
    "                    lex = re.findall('lex=\"(.*?)\"', el)[0]\n",
    "                    post[lex] = trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_sentence(s, wordlist, models, grams_N, grams_V):\n",
    "    words = [el.lower() for el in nltk.word_tokenize(s)]\n",
    "   # print(words)\n",
    "    analyses = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            analyses.append(wordlist[word])\n",
    "        except KeyError:\n",
    "            if word.isdigit():\n",
    "                analyses.append([(word, word, 'NUM')])\n",
    "            else:\n",
    "                analyses.append([])\n",
    "    predicates = find_predicate(analyses, models) #находим предикат\n",
    " #   print(1)\n",
    "    analyses = drop_attr(analyses) #соединяем прил и числ с существительными\n",
    "    analyses = drop_post(analyses) #cоединяем послелоги с сущ\n",
    "  #  print(2)\n",
    "\n",
    "   # print(analyses)\n",
    "    new_ana = []\n",
    "    for ana in analyses:\n",
    "        new_ana.append(list(set(ana)))\n",
    " #   print(new_ana)\n",
    "\n",
    "\n",
    "    \n",
    "    #return analyses, predicates\n",
    "    args = find_args(new_ana, models, predicates) #находим все аргументы в соответствии с правилами\n",
    "    #print(args)\n",
    "    \n",
    "    X = collect_X(analyses, predicates, grams_N, grams_V)\n",
    "    return X, args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_post(analyses):\n",
    "    analyses2 = []\n",
    "    for i in range(len(analyses)):\n",
    "        analyses2.append([])\n",
    "        for el in analyses[i]:\n",
    "            if 'POST' in el[2] or 'rel_n' in el[2]:\n",
    "                try:\n",
    "                    for k in analyses2[-2]:\n",
    "                        if ('N' in k[2] or 'PRO' in k[2] or 'V' in k[2]):\n",
    "                            analyses2[-1].append((k[0] + ' ' + el[0], el[1], el[2]))\n",
    "                            analyses2[-2] = []\n",
    "                except IndexError:\n",
    "                    pass\n",
    "            else:\n",
    "                analyses2[-1].append(el)\n",
    "    ana3 = [x for x in analyses2 if x != []]\n",
    "    return ana3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_attr(analyses):\n",
    "    analyses2 = []\n",
    "    #print(analyses)\n",
    "    for i in range(len(analyses)):\n",
    "        analyses2.append([])\n",
    "      #  print(analyses[i])\n",
    "        for el in analyses[i]:\n",
    "       #     print(el)\n",
    "            if 'N' in el[2]:\n",
    "                try:\n",
    "                    for k in analyses2[-2]:\n",
    "        #                print(k)\n",
    "                        if 'ADJ' in k[2] or 'NUM' in k[2] or 'ADJPRO' in k[2] or ('N' in k[2] and ('nom' in k[2])) or (('N' in k[2] or 'PRO' in k[2]) and ('gen' in k[2])) or ('ptcp' in k[2]):\n",
    "                                \n",
    "                            analyses2[-2] = []\n",
    "                            analyses2[-1].append((k[0] + ' ' + el[0], el[1], el[2]))\n",
    "                            #analyses2.remove(analyses2[-1])\n",
    "                    if analyses2[-1] == []:\n",
    "                        test_copy = copy.copy(analyses[i])\n",
    "                        analyses2[-1] = test_copy\n",
    "                except IndexError:\n",
    "                    analyses2[-1].append(el)\n",
    "            else:\n",
    "                analyses2[-1].append(el)\n",
    "    ana3 = [x for x in analyses2 if x != []]\n",
    "    return ana3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "здесь прописать для причастия и дериваций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_predicate(analyses, models):\n",
    "    predicates = []\n",
    "    for i in range(len(analyses)):\n",
    "        for ana in analyses[i]:\n",
    "            lemma = ana[1]\n",
    "            if lemma in models:\n",
    "                predicates.append(ana + (i,))\n",
    "    return predicates\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_args(analyses, models, predicates):\n",
    "    args = []\n",
    "#    print(analyses)\n",
    "    for pred in predicates:\n",
    "      #  print(pred[0])\n",
    "        model = models[pred[1]]\n",
    "        for el in analyses:\n",
    "            for ana in el:\n",
    "                i = 0\n",
    "                if ana[0] != pred[0]:\n",
    "                    for key in model:\n",
    "                        if key in ana[2] or key in ana[1]:\n",
    "                            if ('1' in pred[2] or '2' in pred[2]) and 'nom' in ana[2]:\n",
    "                                if (ana[1] == 'мон' and '1' in pred[2] and 'sg' in pred[2]) or (ana[1] == 'ми' and '1' in pred[2] and 'pl' in pred[2]) or (ana[1] == 'тон' and '2' in pred[2] and 'sg' in pred[2]) or (ana[1] == 'тӥ' and '2' in pred[2] and 'pl' in pred[2]):\n",
    "                                    args.append([ana, pred, model[key]])\n",
    "                            else:\n",
    "                                args.append([ana, pred, model[key]])\n",
    "                      #      print(model[key] + ' - ' + str(ana))\n",
    "                            i = 1\n",
    "                    if i == 0:\n",
    "                        for p in post:\n",
    "                            if ana[0].endswith(p) and ('rel_n' in ana[2] or 'POST' in ana[2]):\n",
    "                                args.append([ana, pred, post[p]])\n",
    " #   print(analyses, predicates, args)\n",
    "                       #        print(post[p] + ' - ' + str(ana))\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_X(analyses, predicates, grams_N, grams_V):\n",
    "    X = []\n",
    "    for pred in predicates:\n",
    "        for i in range(len(analyses)):\n",
    "            for ana in analyses[i]:\n",
    "                if ana[0] != pred[0]:\n",
    "                    X.append([])\n",
    "                    X[-1].append(ana)\n",
    "              #      print(X[-1])\n",
    "                    X[-1].append(pred)\n",
    "                #    print(X[-1])\n",
    "                    X[-1].append(i - pred[3])\n",
    "                 #   print(X[-1])\n",
    "                    #X[-1].append(ana[2])\n",
    "                  #  print(X[-1])\n",
    "                   # for gr in grams_V:\n",
    "                    #    if gr in ana[2]:\n",
    "                     #       X[-1].append(1)\n",
    "                      #  else:\n",
    "                       #     X[-1].append(0)\n",
    "           #         for gr in grams_V:\n",
    "            #            if gr in pred[2]:\n",
    "             #               X[-1].append(1)\n",
    "              #          else:\n",
    "               #             X[-1].append(0)\n",
    "                   # X[-1].append(pred[2])\n",
    "                    #print(X[-1])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b = parse_sentence('Ува ёросын нуналлы быдэ 4-5 бригадаос шуныт сётӥсь гумыосты воштон бордын ужало.', wordlist, models, grams_N, grams_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[('ува ёросын', 'ёрос', ('N', 'sg', 'loc')),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   -7],\n",
       "  [('нуналлы быдэ', 'быдэ', ('POST',)),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   -6],\n",
       "  [('бригадаос', 'бригада', ('N', 'rus', 'pl', 'nom')),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   -5],\n",
       "  [('шуныт', 'шуныт', ('ADJ',)),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   -4],\n",
       "  [('шуныт', 'шуныт', ('ADV',)),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   -4],\n",
       "  [('сётӥсь гумыосты', 'гумы', ('N', 'pl', 'acc')),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   -3],\n",
       "  [('воштон бордын', 'борд', ('N', 'rel_n', 'sg', 'loc')),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   -2],\n",
       "  [('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '1', 'sg', 'fut')),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   -1],\n",
       "  [('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs')),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   -1],\n",
       "  [('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg')),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   -1],\n",
       "  [('ува ёросын', 'ёрос', ('N', 'sg', 'loc')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '1', 'sg', 'fut'), 11),\n",
       "   -11],\n",
       "  [('нуналлы быдэ', 'быдэ', ('POST',)),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '1', 'sg', 'fut'), 11),\n",
       "   -10],\n",
       "  [('бригадаос', 'бригада', ('N', 'rus', 'pl', 'nom')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '1', 'sg', 'fut'), 11),\n",
       "   -9],\n",
       "  [('шуныт', 'шуныт', ('ADJ',)),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '1', 'sg', 'fut'), 11),\n",
       "   -8],\n",
       "  [('шуныт', 'шуныт', ('ADV',)),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '1', 'sg', 'fut'), 11),\n",
       "   -8],\n",
       "  [('сётӥсь гумыосты', 'гумы', ('N', 'pl', 'acc')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '1', 'sg', 'fut'), 11),\n",
       "   -7],\n",
       "  [('воштон бордын', 'борд', ('N', 'rel_n', 'sg', 'loc')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '1', 'sg', 'fut'), 11),\n",
       "   -6],\n",
       "  [('ува ёросын', 'ёрос', ('N', 'sg', 'loc')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs'), 11),\n",
       "   -11],\n",
       "  [('нуналлы быдэ', 'быдэ', ('POST',)),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs'), 11),\n",
       "   -10],\n",
       "  [('бригадаос', 'бригада', ('N', 'rus', 'pl', 'nom')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs'), 11),\n",
       "   -9],\n",
       "  [('шуныт', 'шуныт', ('ADJ',)),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs'), 11),\n",
       "   -8],\n",
       "  [('шуныт', 'шуныт', ('ADV',)),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs'), 11),\n",
       "   -8],\n",
       "  [('сётӥсь гумыосты', 'гумы', ('N', 'pl', 'acc')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs'), 11),\n",
       "   -7],\n",
       "  [('воштон бордын', 'борд', ('N', 'rel_n', 'sg', 'loc')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs'), 11),\n",
       "   -6],\n",
       "  [('ува ёросын', 'ёрос', ('N', 'sg', 'loc')),\n",
       "   ('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg'),\n",
       "    11),\n",
       "   -11],\n",
       "  [('нуналлы быдэ', 'быдэ', ('POST',)),\n",
       "   ('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg'),\n",
       "    11),\n",
       "   -10],\n",
       "  [('бригадаос', 'бригада', ('N', 'rus', 'pl', 'nom')),\n",
       "   ('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg'),\n",
       "    11),\n",
       "   -9],\n",
       "  [('шуныт', 'шуныт', ('ADJ',)),\n",
       "   ('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg'),\n",
       "    11),\n",
       "   -8],\n",
       "  [('шуныт', 'шуныт', ('ADV',)),\n",
       "   ('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg'),\n",
       "    11),\n",
       "   -8],\n",
       "  [('сётӥсь гумыосты', 'гумы', ('N', 'pl', 'acc')),\n",
       "   ('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg'),\n",
       "    11),\n",
       "   -7],\n",
       "  [('воштон бордын', 'борд', ('N', 'rel_n', 'sg', 'loc')),\n",
       "   ('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg'),\n",
       "    11),\n",
       "   -6]],\n",
       " [[('бригадаос', 'бригада', ('N', 'rus', 'pl', 'nom')),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   'agent'],\n",
       "  [('сётӥсь гумыосты', 'гумы', ('N', 'pl', 'acc')),\n",
       "   ('сётӥсь', 'сётыны', ('V', 'I', 'tr', 'with_dat', 'ptcp', 'act'), 7),\n",
       "   'patient'],\n",
       "  [('ува ёросын', 'ёрос', ('N', 'sg', 'loc')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '1', 'sg', 'fut'), 11),\n",
       "   'location'],\n",
       "  [('воштон бордын', 'борд', ('N', 'rel_n', 'sg', 'loc')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '1', 'sg', 'fut'), 11),\n",
       "   'location'],\n",
       "  [('ува ёросын', 'ёрос', ('N', 'sg', 'loc')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs'), 11),\n",
       "   'location'],\n",
       "  [('бригадаос', 'бригада', ('N', 'rus', 'pl', 'nom')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs'), 11),\n",
       "   'agent'],\n",
       "  [('воштон бордын', 'борд', ('N', 'rel_n', 'sg', 'loc')),\n",
       "   ('ужало', 'ужаны', ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs'), 11),\n",
       "   'location'],\n",
       "  [('ува ёросын', 'ёрос', ('N', 'sg', 'loc')),\n",
       "   ('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg'),\n",
       "    11),\n",
       "   'location'],\n",
       "  [('бригадаос', 'бригада', ('N', 'rus', 'pl', 'nom')),\n",
       "   ('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg'),\n",
       "    11),\n",
       "   'agent'],\n",
       "  [('воштон бордын', 'борд', ('N', 'rel_n', 'sg', 'loc')),\n",
       "   ('ужало',\n",
       "    'ужаны',\n",
       "    ('V', 'II', 'intr', 'with_instr', '3', 'pl', 'prs', 'neg'),\n",
       "    11),\n",
       "   'location']])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbs = open('verbs.csv', 'r', encoding = 'utf-8').read().split('\\n') #модели управления 20 частотных глаголов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ужаны\\tV,II,intr,with_ins\\tработать\\targ0\\tagent\\tnom'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in verbs:\n",
    "    line = line.split('\\t')\n",
    "    if line[0]:\n",
    "        if line[0] not in models:\n",
    "            models[line[0]] = {}\n",
    "        models[line[0]][line[5]] = line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'басьтыны': {'abl': 'source',\n",
       "  'acc': 'patient',\n",
       "  'el': 'source',\n",
       "  'ill': 'goal',\n",
       "  'ins': 'price/manner',\n",
       "  'loc': 'source',\n",
       "  'nom': 'agent/patient'},\n",
       " 'валаны': {'acc': 'content/patient',\n",
       "  'clause': 'content/patient',\n",
       "  'nom': 'agent'},\n",
       " 'вераны': {'acc': 'content',\n",
       "  'clause': 'content',\n",
       "  'dat': 'recipient',\n",
       "  'ins': 'manner',\n",
       "  'nom': 'agent',\n",
       "  'сярысь': 'theme'},\n",
       " 'ветлыны': {'el': 'source',\n",
       "  'ill': 'goal',\n",
       "  'ins': 'manner/partner',\n",
       "  'loc': 'location',\n",
       "  'nom': 'agent',\n",
       "  'prol': 'location'},\n",
       " 'карыны': {'acc': 'patient', 'nom': 'agent'},\n",
       " 'кутыны': {'acc': 'patient',\n",
       "  'ill': 'goal',\n",
       "  'ins': 'instrument',\n",
       "  'nom': 'agent'},\n",
       " 'лэсьтыны': {'acc': 'patient', 'ins': 'instrument', 'nom': 'agent'},\n",
       " 'поттыны': {'acc': 'patient',\n",
       "  'el': 'source',\n",
       "  'ill': 'goal',\n",
       "  'ins': 'manner',\n",
       "  'nom': 'agent'},\n",
       " 'потыны': {'el': 'source', 'ill': 'goal', 'nom': 'agent'},\n",
       " 'пуктыны': {'acc': 'patient', 'ill': 'goal', 'ins': 'manner', 'nom': 'agent'},\n",
       " 'пырыны': {'el': 'source', 'ill': 'goal', 'nom': 'agent'},\n",
       " 'сётыны': {'acc': 'patient',\n",
       "  'dat': 'recipient',\n",
       "  'ins': 'instrument',\n",
       "  'nom': 'agent'},\n",
       " 'ужаны': {'ins': 'status/instrument/partner',\n",
       "  'loc': 'location',\n",
       "  'nom': 'agent'},\n",
       " 'улыны': {'ins': 'partner', 'loc': 'location', 'nom': 'agent'},\n",
       " 'утьыны': {'acc': 'patient', 'ins': 'instrument', 'nom': 'agent'},\n",
       " 'учкыны': {'acc': 'theme', 'clause': 'goal', 'ill': 'goal', 'nom': 'agent'},\n",
       " 'шедьтыны': {'acc': 'patient', 'el': 'location', 'nom': 'agent'},\n",
       " 'шуыны': {'acc': 'content',\n",
       "  'clause': 'content',\n",
       "  'dat': 'recipient',\n",
       "  'ins': 'manner',\n",
       "  'nom': 'agent',\n",
       "  'сярысь': 'theme'},\n",
       " 'юрттыны': {'dat': 'recipient', 'inf': 'theme', 'nom': 'agent'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#послелоги\n",
    "post = {}\n",
    "with open('post.txt', 'r', encoding = 'utf-8') as postfile:\n",
    "    f = postfile.read().split('\\n')\n",
    "    for line in f:\n",
    "        line = line.split('\\t')\n",
    "        post[line[0]] = line[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = open('examples.txt', 'r', encoding = 'utf-8').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "847"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ува ёросын нуналлы быдэ 4-5 бригадаос шуныт сётӥсь гумыосты воштон бордын ужало.'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_ex = []\n",
    "for ex in examples:\n",
    "    if len(ex) <= 80:\n",
    "        short_ex.append(ex)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, args = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ex in short_ex:\n",
    "    ex_X, ex_args = parse_sentence(ex, wordlist, models, grams_N, grams_V)\n",
    "    X += ex_X\n",
    "    args += ex_args\n",
    "    \n",
    "    ex_y = []\n",
    "    for i in range(len(ex_X)):\n",
    "        for j in ex_args:\n",
    "            #print(ex_X[i][:2], j[:2])\n",
    "            if ex_X[i][:2] == j[:2]:\n",
    "                ex_y.append(j[2])\n",
    "                break\n",
    "        #print(len(ex_y), i)\n",
    "        if len(ex_y) < i+1:\n",
    "            ex_y.append(0)\n",
    "        #print(i[0], j[0], i[1], j[1])\n",
    "         #   else:\n",
    "          #      y.append(0)\n",
    "    y += ex_y\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9480"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('татын', 'татын', ('ADVPRO', 'loc')),\n",
       " ('ужаськомы',\n",
       "  'ужаны',\n",
       "  ('V', 'II', 'intr', 'with_instr', '1', 'pl', 'prs'),\n",
       "  7),\n",
       " -7]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('татын', 'татын', ('ADVPRO', 'loc')),\n",
       " ('ужаськомы',\n",
       "  'ужаны',\n",
       "  ('V', 'II', 'intr', 'with_instr', '1', 'pl', 'prs'),\n",
       "  7),\n",
       " 'location']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_X = []\n",
    "for el in X:\n",
    "    a = [el[0][0], el[1][0], el[2]]\n",
    "    for gr in grams_V:\n",
    "        if gr in el[0][2]:\n",
    "            a.append(1)\n",
    "        else:\n",
    "            a.append(0)\n",
    "    for gr in grams_V:\n",
    "        if gr in el[1][2]:\n",
    "            a.append(1)\n",
    "        else:\n",
    "            a.append(0)\n",
    "    new_X.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'location'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 'recipient',\n",
       " 'source',\n",
       " 'manner/partner',\n",
       " 'partner',\n",
       " 'manner',\n",
       " 'instrument',\n",
       " 'price/manner',\n",
       " 'goal',\n",
       " 'time',\n",
       " 'content/patient',\n",
       " 'patient',\n",
       " 'theme',\n",
       " 'content',\n",
       " 'location',\n",
       " 'agent',\n",
       " 'agent/patient',\n",
       " 'status/instrument/partner'}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = ''\n",
    "for i in range(len(new_X)):\n",
    "    x = '\\t'.join([str(el) for el in new_X[i]])\n",
    "    s = s + x + '\\t' + str(y[i]) + '\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9480"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('pairs-2.csv', 'w', encoding = 'utf-8')\n",
    "f.write(s) \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('pairs-2.csv', 'r', encoding = 'utf-8')\n",
    "lines = list(set(f.read().split('\\n')))\n",
    "f.close() \n",
    "\n",
    "f = open('pairs-2.csv', 'w', encoding = 'utf-8')\n",
    "f.write('\\n'.join(lines)) \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_X = np.array(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['татын', 'ужаськомы', '-7', ..., '0', '0', '0'],\n",
       "       ['ми', 'ужаськомы', '-6', ..., '0', '0', '0'],\n",
       "       ['мужикеным', 'ужаськомы', '-5', ..., '0', '0', '0'],\n",
       "       ..., \n",
       "       ['азинтыны', 'утьыны', '2', ..., '0', '0', '0'],\n",
       "       ['калыклэсь', 'утьыны', '3', ..., '0', '0', '0'],\n",
       "       ['лулчеберетсэ', 'утьыны', '4', ..., '0', '0', '0']],\n",
       "      dtype='<U40')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('pairs-3.csv', 'r', encoding = 'utf-8')\n",
    "lines = f.read().split('\\n')\n",
    "new_y = [i.split('\\t')[-1] for i in lines] \n",
    "new_X = [i.split('\\t')[2:-2] for i in lines] \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '\\n'.join(short_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('short_ex.txt', 'w', encoding = 'utf-8')\n",
    "f.write(text) \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [x[2:] for x in X_train]\n",
    "X_test = [x[2:] for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.277914723008\n",
      "0.297722488587\n",
      "0.26781252182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenya\\A3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\zhenya\\A3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "   \n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
